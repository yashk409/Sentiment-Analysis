{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemma=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=set(w.rstrip() for w in open('stopwords.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews=BeautifulSoup(open('positive.review').read())\n",
    "positive_reviews=positive_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews=BeautifulSoup(open('negative.review').read())\n",
    "negative_reviews=negative_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    s=s.lower()\n",
    "    tokens=nltk.tokenize.word_tokenize(s)\n",
    "    tokens=[t for t in tokens if len(t)>2]\n",
    "    tokens=[wordnet_lemma.lemmatize(t) for t in tokens]\n",
    "    tokens=[t for t in tokens if t not in stopwords]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_map={}\n",
    "current_index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tokenized=[]\n",
    "negative_tokenized=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in positive_reviews:\n",
    "    tokens=my_tokenizer(review.text)\n",
    "    positive_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token]=current_index\n",
    "            current_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in negative_reviews:\n",
    "    tokens=my_tokenizer(review.text)\n",
    "    negative_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token]=current_index\n",
    "            current_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_vector(tokens, label):\n",
    "    x=np.zeros(len(word_index_map)+1)\n",
    "    for t in tokens:\n",
    "        i=word_index_map[t]\n",
    "        x[i]+=1\n",
    "    x=x/x.sum()\n",
    "    x[-1]=label\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(positive_tokenized)+len(negative_tokenized)\n",
    "data=np.zeros((N,len(word_index_map)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for tokens in positive_tokenized:\n",
    "    xy=tokens_to_vector(tokens,1)\n",
    "    data[i,:]=xy\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokens in negative_tokenized:\n",
    "    xy=tokens_to_vector(tokens,0)\n",
    "    data[i,:]=xy\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "X=data[:,:-1]\n",
    "Y=data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=X[:-1000,]\n",
    "ytrain=Y[:-1000,]\n",
    "xtest=X[-1000:,]\n",
    "ytest=Y[-1000:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 0.72\n"
     ]
    }
   ],
   "source": [
    "model=LogisticRegression(solver='lbfgs')\n",
    "model.fit(xtrain,ytrain)\n",
    "print(\"Accuracy of Logistic Regression:\",model.score(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purchased -0.724598292900975\n",
      "unit -1.2979438204282727\n",
      "bad -3.1365105040974464\n",
      "cable 0.5757178615496364\n",
      "minute -1.4389003589411649\n",
      "time -1.0239358441986353\n",
      "save -0.6746804566377006\n",
      "clean 1.5933510078546589\n",
      "'ve 1.248369287272526\n",
      "month -1.6213353343331054\n",
      "simple 0.8600882054435354\n",
      "light 0.5391282828761181\n",
      "sound 0.6221416982771426\n",
      "lot 1.1362664085002327\n",
      "you 2.2589885594394112\n",
      "n't -3.987761925842323\n",
      "easy 4.877339399254914\n",
      "quality 1.5257464554627485\n",
      "item -1.1498044035630024\n",
      "wa -4.430350691936134\n",
      "perfect 2.304194558203345\n",
      "sturdy 0.5139860167385207\n",
      "collection 0.5271652474464766\n",
      "flimsy -0.5080798408180156\n",
      "fast 1.2827448700365423\n",
      "ha 1.5680456492535475\n",
      "complaint 0.656127622911944\n",
      "price 3.454942729663306\n",
      "value 0.7634991358027196\n",
      "money -2.2880520597665\n",
      "memory 0.863874083437682\n",
      "game 0.5897352793617908\n",
      "buy -1.3002107039442603\n",
      "... -1.7294762983290843\n",
      "thank 0.5687466005167601\n",
      "review -1.502484750588869\n",
      "fine 0.5004058380020165\n",
      "bit 0.8591558294211723\n",
      "happy 1.0762869378823128\n",
      "super 0.5234826619182064\n",
      "pretty 0.551602695833221\n",
      "avoid -0.5377828881400806\n",
      "doe -2.146294748903689\n",
      "pleased 0.8268805060356302\n",
      "highly 2.3647892475298433\n",
      "recommend 1.5881969777799645\n",
      "fit 0.765986564123863\n",
      "customer -0.7762531595937024\n",
      "support -0.9663581342089651\n",
      "replacement -0.7507652935351157\n",
      "little 1.2981648011729556\n",
      "heavy 0.6988793805278869\n",
      "unless -0.5351500200148235\n",
      "slow -0.576017469401544\n",
      "amazing 1.1474262442433043\n",
      "worth 0.8398609867396561\n",
      "returned -1.384228936058625\n",
      "excellent 2.8745417178228516\n",
      "extra 0.7099154592217695\n",
      "love 5.4493168291791205\n",
      "feature 0.9202074437987794\n",
      "home 0.7920563649311606\n",
      "difficult -0.5770604004735763\n",
      "recommended 0.5685051691797223\n",
      "piece -0.7427040891817838\n",
      "cake 0.5430214986842865\n",
      "useless -0.8486273916023017\n",
      "however -0.8255436990781658\n",
      "instead -1.0390638831443197\n",
      "quickly 0.5879126389431992\n",
      "handy 0.5772238374681662\n",
      "week -0.639892899461347\n",
      "actually -0.668481085436296\n",
      "size 1.3330873087347412\n",
      "using 0.5843782403667664\n",
      "guess -0.672935075832574\n",
      "else -0.7418627320162184\n",
      "machine -0.7286442782240601\n",
      "nice 1.0538045148705868\n",
      "broke -1.4071984401757165\n",
      "set 0.6934219881543351\n",
      "watch 0.8334213155802406\n",
      "friend 0.5324786486237642\n",
      "poor -1.6142668119324879\n",
      "fantastic 0.857368739118584\n",
      "disappointed -1.9041323761925328\n",
      "season 0.9651190471003934\n",
      "easily 0.6211083256241781\n",
      "then -2.4571444093144117\n",
      "called -0.8119984807004045\n",
      "tried -1.559197995674844\n",
      "call -0.5126973522230908\n",
      "started -1.0552814245591586\n",
      "horrible -1.1586656467124476\n",
      "perfectly 0.8461482711489792\n",
      "poorly -0.9370961037743512\n",
      "trying -0.75224072380908\n",
      "music 0.5527132876070573\n",
      "performance 0.5239027789964049\n",
      "book -0.527365302144407\n",
      "try -1.2778556530301508\n",
      "life 0.7925174167704562\n",
      "space 0.8801330428008435\n",
      "thin -0.6365624427026658\n",
      "comfortable 0.7301408649645722\n",
      "store 0.829373145077878\n",
      "bottom -0.6161643430616949\n",
      "rest -0.5981825473718563\n",
      "maybe -0.9427746688421605\n",
      "half -1.0346924853826482\n",
      "hour -0.7358520968058696\n",
      "idea -0.7200511081697402\n",
      "unfortunately -0.9560085378406186\n",
      "liked 0.5387396513385236\n",
      "speaker 0.7736323341125572\n",
      "cheap -0.9580587562389112\n",
      "received -0.6647153807004635\n",
      "warranty -0.8153629991235355\n",
      "plenty 0.508763984794803\n",
      "world 0.7910785137056789\n",
      "awesome 1.0309037388558462\n",
      "plastic -0.9389512020706489\n",
      "worse -0.9259764144750721\n",
      "wonderful 1.9652671739389833\n",
      "especially 0.8512264424083952\n",
      "overall 0.7736043170651661\n",
      "error -0.59865634621707\n",
      "special 0.6443040122797953\n",
      "loved 1.2415081938592405\n",
      "satisfied 0.8237249181016448\n",
      "stopped -0.9141789101656869\n",
      "beat 0.5900228144093883\n",
      "beautifully 0.5061017277159672\n",
      "condition 0.5249184678238094\n",
      "junk -0.7509798227425243\n",
      "barely -0.6180832621367935\n",
      "died -0.7922658616078748\n",
      "mistake -0.6351079918946673\n",
      "type -0.5137079559348882\n",
      "defective -0.5886002056039308\n",
      "beautiful 0.8895830275976605\n",
      "disappointing -0.839415710612451\n",
      "fun 0.6941017122533756\n",
      "glad 0.702174624910027\n",
      "gift 0.534792063320837\n",
      "family 1.5322965882672497\n",
      "send -0.5979380918835508\n",
      "dull -0.7178531200787324\n",
      "series 0.5381958565869847\n",
      "add 0.6200039857875811\n",
      "returning -0.7952674641220344\n",
      "solid 0.6025526929064884\n",
      "sorry -0.5539450059158956\n",
      "terrible -1.0614333320820168\n",
      "kitchen 0.6837408910497589\n",
      "enjoy 0.7769807900298696\n",
      "return -1.8774123455666907\n",
      "food 0.6225070981830878\n",
      "favorite 1.4981188134348207\n",
      "failed -0.5133916187479117\n",
      "awful -0.7760587423229748\n",
      "son 0.8514485988440172\n",
      "writing -0.6152395498161668\n",
      "page -0.7028786036092015\n",
      "attempt -0.543031783337322\n",
      "stupid -0.7508159650093288\n",
      "suck -0.6743628462288378\n",
      "waste -2.8464358951316493\n",
      "worst -1.8119496929951784\n",
      "enjoyed 1.0341708075363012\n",
      "story 0.7330925900457722\n",
      "impossible -0.5873128553484167\n",
      "cooking 0.8234094504393105\n",
      "refund -1.0532694254317407\n",
      "knife 1.2016562546795317\n",
      "ridiculous -0.5213329104562485\n",
      "episode 0.5872875390188099\n",
      "plot -0.546287157037802\n",
      "acting -0.5880553058271543\n",
      "boring -1.5866124138463016\n",
      "disappointment -0.8468557765380117\n"
     ]
    }
   ],
   "source": [
    "threshold=0.5\n",
    "for word,index in word_index_map.items():\n",
    "    weight=model.coef_[0][index]\n",
    "    if weight>threshold or weight< -threshold:\n",
    "        print (word,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model2=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MultinomialNB 0.79\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of MultinomialNB',model2.score(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of SVM\",clf.score(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
